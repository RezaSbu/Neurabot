from pydantic import BaseModel, Field
from typing import Optional, List
from app.db import search_vector_db
from app.openai import get_embedding
import numpy as np

class QueryKnowledgeBaseTool(BaseModel):
    query_input: str = Field(..., description="User query")
    query_category: Optional[str] = Field(None)
    price_min: Optional[float] = Field(None)
    price_max: Optional[float] = Field(None)
    price_tolerance: Optional[float] = Field(500_000)
    brand: Optional[str] = Field(None)
    feature_keywords: Optional[List[str]] = Field(None)
    size_preferences: Optional[List[str]] = Field(None)
    top_k: int = 10

    async def __call__(self, rdb):
        query_vector = await get_embedding(self.query_input)
        results = await search_vector_db(rdb, query_vector, top_k=self.top_k)

        if not results:
            return "âŒ Ù…Ø­ØµÙˆÙ„ÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

        output = []
        for i, chunk in enumerate(results):
            name = chunk.get("text", "Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…")
            doc = chunk.get("doc_name", "")
            score = round(chunk.get("score", 0) * 100, 2)
            chunk_id = chunk.get("chunk_id", "")

            block = (
                f"{i+1}. **{name}**\n"
                f"ğŸ“„ Ø³Ù†Ø¯: {doc}\n"
                f"ğŸ“Œ Ø¨Ø®Ø´: {chunk_id}\n"
                f"ğŸ” Ø´Ø¨Ø§Ù‡Øª: {score}%\n"
            )
            output.append(block)

        return "\n\n---\n\n".join(output) + "\n\n---\nØ§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ú†Ø·ÙˆØ± Ø¨ÙˆØ¯Ù†ØŸ Ù…ÙˆØ±Ø¯ Ø¯ÛŒÚ¯Ù‡â€ŒØ§ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒØŸ ğŸ˜Š"
