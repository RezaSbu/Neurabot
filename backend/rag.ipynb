{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.loader import add_docs_to_knowledge_base\n",
    "from app.db import reset_db, create_vectors_index, search_vector_db\n",
    "from app.openai import get_embedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index idx:vectors created successfully\n"
     ]
    }
   ],
   "source": [
    "reset_db()\n",
    "create_vectors_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 PDF documents\n",
      "\n",
      "Splitting documents into chunks\n",
      "Inception.pdf: 127 chunks\n",
      "\n",
      "Total chunks: 127\n",
      "Min chunk size: 351 tokens\n",
      "Max chunk size: 512 tokens\n",
      "Average chunk size: 496 tokens\n",
      "\n",
      "Embedding chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:02<00:00, 49.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding chunks to vector DB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "await add_docs_to_knowledge_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is the most resilient parasite?'\n",
    "vector = await get_embedding(query)\n",
    "query_vector = np.array(vector, dtype=np.float32).tobytes()\n",
    "search_vector_db(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from app.openai import chat, token_size\n",
    "from app.tools import QueryKnowledgeBaseTool\n",
    "from app.prompts import MAIN_SYSTEM_PROMPT, RAG_SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[ChatCompletionMessageToolCall(id='call_Qb4rkxNAknxdTOfnpBUYnz19', function=Function(arguments='{\"query_input\":\"What is the most resilient parasite?\"}', name='QueryKnowledgeBaseTool'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "chat_messages = []\n",
    "system_message = {'role': 'system', 'content': MAIN_SYSTEM_PROMPT}\n",
    "openai_tools = [QueryKnowledgeBaseTool.openai_tool_schema()]\n",
    "user_message = {'role': 'user', 'content': \"What's the most resilient parasite?\"}\n",
    "chat_messages.append(user_message)\n",
    "content, tool_calls = await chat(\n",
    "    messages=[system_message, *chat_messages],\n",
    "    tools=openai_tools,\n",
    "    tool_choice='auto'\n",
    ")\n",
    "print(content)\n",
    "print(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = tool_calls[0]\n",
    "kb_tool = QueryKnowledgeBaseTool(**json.loads(tool_call.function.arguments))\n",
    "kb_result = await kb_tool()\n",
    "chat_messages.extend([\n",
    "    {'role': 'assistant', 'content': content, 'tool_calls': tool_calls},\n",
    "    {'role': 'tool', 'tool_call_id': tool_call.id, 'content': kb_result}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most resilient parasite is an idea. Once an idea has taken hold in the brain, it becomes almost impossible to eradicate. As Cobb explains, \"A person can cover it up, ignore it - but it stays there.\" This highlights the idea's contagious and persistent nature, making it a powerful form of \"parasite\" in a metaphorical sense.\n"
     ]
    }
   ],
   "source": [
    "rag_system_message = {'role': 'system', 'content': RAG_SYSTEM_PROMPT}\n",
    "content, tool_calls = await chat(messages=[rag_system_message, *chat_messages])\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
