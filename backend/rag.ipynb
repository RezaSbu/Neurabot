{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.loader import add_docs_to_knowledge_base\n",
    "from app.db import reset_db, create_vectors_index, count_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index idx:vectors created successfully\n"
     ]
    }
   ],
   "source": [
    "await reset_db()\n",
    "await create_vectors_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 PDF documents\n",
      "\n",
      "Splitting documents into chunks\n",
      "Inception.pdf: 127 chunks\n",
      "\n",
      "Total chunks: 127\n",
      "Min chunk size: 351 tokens\n",
      "Max chunk size: 512 tokens\n",
      "Average chunk size: 496 tokens\n",
      "\n",
      "Embedding chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:02<00:00, 45.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding chunks to vector DB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "await add_docs_to_knowledge_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors: 127\n"
     ]
    }
   ],
   "source": [
    "total_vectors = await count_vectors()\n",
    "print(f'Total vectors: {total_vectors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from app.openai import chat\n",
    "from app.tools import QueryKnowledgeBaseTool\n",
    "from app.prompts import MAIN_SYSTEM_PROMPT, RAG_SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[ChatCompletionMessageToolCall(id='call_QCBVgmYUq2XO7BEF8G9qIawU', function=Function(arguments='{\"query_input\":\"What is the most resilient parasite?\"}', name='QueryKnowledgeBaseTool'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "chat_messages = []\n",
    "system_message = {'role': 'system', 'content': MAIN_SYSTEM_PROMPT}\n",
    "openai_tools = [QueryKnowledgeBaseTool.openai_tool_schema()]\n",
    "user_message = {'role': 'user', 'content': \"What's the most resilient parasite?\"}\n",
    "chat_messages.append(user_message)\n",
    "content, tool_calls = await chat(\n",
    "    messages=[system_message, *chat_messages],\n",
    "    tools=openai_tools,\n",
    "    tool_choice='auto'\n",
    ")\n",
    "print(content)\n",
    "print(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = tool_calls[0]\n",
    "kb_tool = QueryKnowledgeBaseTool(**json.loads(tool_call.function.arguments))\n",
    "kb_result = await kb_tool()\n",
    "chat_messages.extend([\n",
    "    {'role': 'assistant', 'content': content, 'tool_calls': tool_calls},\n",
    "    {'role': 'tool', 'tool_call_id': tool_call.id, 'content': kb_result}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most resilient parasite is described as an idea. Once an idea takes hold in the brain, it becomes almost impossible to eradicate. As Cobb explains, \"A person can cover it up, ignore it - but it stays there.\" This highlights the tenacity of ideas compared to other forms of information, which can be forgotten.\n"
     ]
    }
   ],
   "source": [
    "rag_system_message = {'role': 'system', 'content': RAG_SYSTEM_PROMPT}\n",
    "content, tool_calls = await chat(messages=[rag_system_message, *chat_messages])\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
