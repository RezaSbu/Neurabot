{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from pdfminer.high_level import extract_text\n",
    "import numpy as np\n",
    "from app.splitter import TextSplitter\n",
    "from app.openai import token_size, get_embeddings, get_embedding\n",
    "from app.loader import load_docs\n",
    "from app.config import settings\n",
    "from redis import Redis\n",
    "from redis.commands.search.field import NumericField, TagField, TextField, VectorField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.json.path import Path\n",
    "from redis.commands.search.query import Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DIR = 'data/docs'\n",
    "\n",
    "def load_docs():\n",
    "    docs = []\n",
    "    pdf_files = [f for f in os.listdir(DOCS_DIR) if f.endswith('.pdf')]\n",
    "    for filename in tqdm(pdf_files):\n",
    "        file_path = os.path.join(DOCS_DIR, filename)\n",
    "        text = extract_text(file_path)\n",
    "        docs.append((filename, text))\n",
    "    print(f'Loaded {len(docs)} PDF documents')\n",
    "\n",
    "    chunks = []\n",
    "    text_splitter = TextSplitter(chunk_size=512, chunk_overlap=150)\n",
    "    print('\\nSplitting documents into chunks')\n",
    "    for doc_name, doc_text in docs:\n",
    "        doc_id = str(uuid.uuid4())[:8]\n",
    "        doc_chunks = text_splitter.split(doc_text)\n",
    "        for chunk_idx, chunk_text in enumerate(doc_chunks):\n",
    "            chunk = {\n",
    "                'id': f'{doc_id}:{chunk_idx:04}',\n",
    "                'text': chunk_text,\n",
    "                'doc_name': doc_name,\n",
    "                'vector': None\n",
    "            }\n",
    "            chunks.append(chunk)\n",
    "        print(f'{doc_name}: {len(doc_chunks)} chunks')\n",
    "    chunk_sizes = [token_size(c['text']) for c in chunks]\n",
    "    print(f'\\nTotal chunks: {len(chunks)}')\n",
    "    print(f'Min chunk size: {min(chunk_sizes)} tokens')\n",
    "    print(f'Max chunk size: {max(chunk_sizes)} tokens')\n",
    "    print(f'Average chunk size: {round(sum(chunk_sizes)/len(chunks))} tokens')\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 PDF documents\n",
      "\n",
      "Splitting documents into chunks\n",
      "Inception.pdf: 127 chunks\n",
      "\n",
      "Total chunks: 127\n",
      "Min chunk size: 351 tokens\n",
      "Max chunk size: 512 tokens\n",
      "Average chunk size: 496 tokens\n"
     ]
    }
   ],
   "source": [
    "chunks = load_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(iterable, batch_size):\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:02<00:00, 55.78it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "print('\\nEmbedding chunks')\n",
    "with tqdm(total=len(chunks)) as pbar:\n",
    "    for batch in batchify(chunks, batch_size=64):\n",
    "        batch_vectors = await get_embeddings([chunk['text'] for chunk in batch])\n",
    "        vectors.extend(batch_vectors)\n",
    "        pbar.update(len(batch))\n",
    "\n",
    "for chunk, vector in zip(chunks, vectors):\n",
    "    chunk['vector'] = np.array(vector, dtype=np.float32).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = Redis(host='localhost', port=6379, decode_responses=True)\n",
    "# r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name='idx:vdb', prefix='vdb:'):\n",
    "    schema = (\n",
    "        TextField('text'),\n",
    "        TextField('doc_name'),\n",
    "        VectorField('vector',\n",
    "            'FLAT', {\n",
    "                'TYPE': 'FLOAT32',\n",
    "                'DIM': settings.EMBEDDING_DIMENSIONS,\n",
    "                'DISTANCE_METRIC': 'COSINE',\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    try:\n",
    "        r.ft(index_name).create_index(\n",
    "            fields=schema,\n",
    "            definition=IndexDefinition(prefix=[prefix], index_type=IndexType.HASH)\n",
    "        )\n",
    "        print(f'Index {index_name} created successfully')\n",
    "    except Exception as e:\n",
    "        print(f'Error creating index {index_name}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index idx:vdb created successfully\n"
     ]
    }
   ],
   "source": [
    "create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(items):\n",
    "    pipe = r.pipeline()\n",
    "    for item in items:\n",
    "        key = f'vdb:{item['id']}'\n",
    "        pipe.hset(key, mapping=item)\n",
    "    pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(vector, top_k=3):\n",
    "    query = (\n",
    "        Query(f'(*)=>[KNN {top_k} @vector $vector AS score]')\n",
    "        .sort_by('score')\n",
    "        .return_fields('score', 'id', 'text', 'doc_name')\n",
    "        .paging(0, top_k)\n",
    "        .dialect(2)\n",
    "    )\n",
    "    res = r.ft('idx:vdb').search(query, {'vector': vector})\n",
    "    return res.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What is the most resilient parasite?'\n",
    "vector = await get_embedding(question)\n",
    "vector = np.array(vector, dtype=np.float32).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731605470181 vdb:b7c5dbf9:0001\n",
      "INT. SAME - MOMENTS LATER\n",
      "\n",
      "The Elderly Man watches the Bearded Man WOLF down his food. \n",
      "He SLIDES the handgun down the table towards him.\n",
      "\n",
      "ELDERLY JAPANESE MAN\n",
      "\n",
      "(in English)\n",
      "\n",
      "Are you here to kill me?\n",
      "\n",
      "The Bearded Man glances up at him, then back to his food.\n",
      "\n",
      "\f2.\n",
      "\n",
      "The Elderly Japanese Man picks up the cone between thumb and \n",
      "forefinger.\n",
      "\n",
      "I know what this is.\n",
      "\n",
      "ELDERLY JAPANESE MAN\n",
      "\n",
      "He SPINS it onto a table- it CIRCLES gracefully across the \n",
      "polished ebony... a SPINNING TOP.\n",
      "\n",
      "ELDERLY JAPANESE MAN\n",
      "\n",
      "I’ve seen one before. Many, many \n",
      "years ago...\n",
      "\n",
      "The Elderly Japanese Man STARES at the top mesmerized.\n",
      "\n",
      "ELDERLY JAPANESE MAN\n",
      "\n",
      "It belonged to a man I met in a \n",
      "half-remembered dream...\n",
      "\n",
      "MOVE IN on the GRACEFULLY SPINNING TOP...\n",
      "\n",
      "ELDERLY JAPANESE MAN\n",
      "\n",
      "A man possessed of some radical \n",
      "notions...\n",
      "\n",
      "The Elderly Japanese Man STARES, remembering... \n",
      "\n",
      "What’s the most resilient parasite?\n",
      "\n",
      "COBB (V.O.)\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. SAME ELEGANT DINING ROOM - NIGHT (YEARS EARLIER)\n",
      "\n",
      "The speaker, COBB, is 35, handsome, tailored. A young \n",
      "Japanese man, SAITO, eats as he listens. \n",
      "\n",
      "A bacteria? A virus?\n",
      "\n",
      "COBB\n",
      "\n",
      "Cobb gestures at their feast with his wine glass-\n",
      "\n",
      "An intestinal worm?\n",
      "\n",
      "COBB\n",
      "\n",
      "Saito’s fork pauses, mid-air. Cobb GRINS. A third man is at \n",
      "the table- ARTHUR. He jumps in to save the pitch- \n",
      "\n",
      "What Mr. Cobb is trying to say-\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "An idea.\n",
      "\n",
      "COBB\n",
      "\n",
      "Saito looks at Cobb, curious.\n",
      "\n",
      "\f3.\n",
      "\n",
      "COBB\n",
      "\n",
      "Resilient, highly contagious. Once \n",
      "an idea’s taken hold in the brain \n",
      "it’s almost impossible to \n",
      "eradicate. A person can cover it \n",
      "up, ignore it- but it stays there. \n",
      "\n",
      "SAITO\n",
      "But surely-to forget...?\n",
      "\n",
      "COBB\n",
      "\n",
      "Information, yes. But an idea? \n",
      "Fully formed, understood? That \n",
      "sticks...\n",
      "\n",
      "(taps forehead)\n",
      "\n",
      "In there, somewhere.\n",
      "\n",
      "For someone like you to steal?\n",
      "\n",
      "SAITO\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "\n",
      "************************************************\n",
      "\n",
      "\n",
      "0.821313679218 vdb:b7c5dbf9:0066\n",
      "How could they be trained?\n",
      "\n",
      "ARIADNE \n",
      "\n",
      "ARTHUR\n",
      "\n",
      "Fischer's had an extractor teach \n",
      "his mind to defend itself. His \n",
      "subconscious is militarized. It \n",
      "should've shown on the research-\n",
      "\n",
      "COBB \n",
      "So why the hell didn't it?!\n",
      "\n",
      "Calm down.\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "COBB\n",
      "\n",
      "Don't tell me to calm down-you were \n",
      "meant to check Fischer's background \n",
      "thoroughly. You can't make this \n",
      "kind of mistake-we're not prepared \n",
      "for this kind of violence-\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "Cobb, we've dealt with sub-security \n",
      "before. We just have to be more-\n",
      "\n",
      "COBB\n",
      "\n",
      "This wasn't part of the plan, Arthur! \n",
      "\n",
      "(points at Saito)\n",
      "\n",
      "He's dying!\n",
      "\n",
      "So we put him out of his misery.\n",
      "\n",
      "EAMES  \n",
      "\n",
      "\fEames steps into the room, pulls his gun and moves over \n",
      "Saito.\n",
      "\n",
      "79.\n",
      "\n",
      "No.\n",
      "\n",
      "COBB\n",
      "\n",
      "EAMES\n",
      "\n",
      "He's in agony. Let's wake him up-\n",
      "\n",
      "Cobb GRABS Eames's arm.\n",
      "\n",
      "COBB\n",
      "\n",
      "No!\n",
      "\n",
      "(they lock eyes) \n",
      "It won't wake him up.\n",
      "\n",
      "EAMES\n",
      "\n",
      "What do you mean, it won't wake \n",
      "him? When you die in a dream you \n",
      "wake up.\n",
      "\n",
      "YUSUF\n",
      "\n",
      "Not from this. We're too heavily \n",
      "sedated to wake up that way.\n",
      "\n",
      "Eames looks at Yusuf, then to Cobb.\n",
      "\n",
      "So what happens if one of us dies?\n",
      "\n",
      "EAMES\n",
      "\n",
      "COBB\n",
      "\n",
      "That person doesn't wake up. Their \n",
      "mind drops into Limbo.\n",
      "\n",
      "Limbo?\n",
      "\n",
      "ARIADNE\n",
      "\n",
      "ARTHUR \n",
      "Unconstructed dream space.\n",
      "\n",
      "ARIADNE \n",
      "What's down there?\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "Raw, infinite subconscious. Nothing \n",
      "there but what was left behind by \n",
      "anyone on the team who's been trapped \n",
      "there before. On this team... just \n",
      "Cobb.\n",
      "\n",
      "How long would we be stuck there?\n",
      "\n",
      "ARIADNE\n",
      "\n",
      "\f80.\n",
      "\n",
      "YUSUF\n",
      "\n",
      "You couldn't even think about \n",
      "trying to escape until the sedation \n",
      "eases-\n",
      "\n",
      "How long?\n",
      "\n",
      "EAMES\n",
      "\n",
      "YUSUF\n",
      "\n",
      "Decades-it could be infinite-I \n",
      "don't know! Ask him-he's the one \n",
      "who's been there before!\n",
      "\n",
      "Eames moves to Cobb. Looks him in the eye.\n",
      "\n",
      "EAMES\n",
      "\n",
      "Great. So now we're stuck in \n",
      "Fischer's mind battling it out with \n",
      "his private army, and if we get hit \n",
      "we're stuck in Limbo 'til our \n",
      "brains dissolve into scrambled egg?\n",
      "\n",
      "Cobb says nothing. Saito groans more loudly.\n",
      "\n",
      "\n",
      "************************************************\n",
      "\n",
      "\n",
      "0.824398577213 vdb:b7c5dbf9:0002\n",
      "What Mr. Cobb is trying to say-\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "An idea.\n",
      "\n",
      "COBB\n",
      "\n",
      "Saito looks at Cobb, curious.\n",
      "\n",
      "\f3.\n",
      "\n",
      "COBB\n",
      "\n",
      "Resilient, highly contagious. Once \n",
      "an idea’s taken hold in the brain \n",
      "it’s almost impossible to \n",
      "eradicate. A person can cover it \n",
      "up, ignore it- but it stays there. \n",
      "\n",
      "SAITO\n",
      "But surely-to forget...?\n",
      "\n",
      "COBB\n",
      "\n",
      "Information, yes. But an idea? \n",
      "Fully formed, understood? That \n",
      "sticks...\n",
      "\n",
      "(taps forehead)\n",
      "\n",
      "In there, somewhere.\n",
      "\n",
      "For someone like you to steal?\n",
      "\n",
      "SAITO\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "Yes. In the dream state, conscious \n",
      "defenses are lowered and your \n",
      "thoughts become vulnerable to \n",
      "theft. It’s called extraction.\n",
      "\n",
      "COBB\n",
      "\n",
      "But, Mr. Saito, we can train your \n",
      "subconscious to defend itself from \n",
      "even the most skilled extractor.\n",
      "\n",
      "How can you do that?\n",
      "\n",
      "SAITO\n",
      "\n",
      "COBB\n",
      "\n",
      "Because I am the most skilled \n",
      "extractor. I know how to search \n",
      "your mind and find your secrets. I \n",
      "know the tricks, and I can teach \n",
      "them to your subconscious so that \n",
      "even when you’re asleep, your guard \n",
      "is never down. \n",
      "\n",
      "Cobb leans forwards. Holding Saito’s gaze.\n",
      "\n",
      "COBB\n",
      "\n",
      "But if I’m going to help you, you \n",
      "have to be completely open to me. \n",
      "I’ll need to know my way around \n",
      "your thoughts better than your \n",
      "wife, your analyst, anyone. \n",
      "\n",
      "(gestures around)\n",
      "\n",
      "If this is a dream and you’ve got a \n",
      "safe full of secrets, I need to \n",
      "know what’s in that safe. For this \n",
      "to work, you have to let me in. \n",
      "\n",
      "\f4.\n",
      "\n",
      "Saito gives this a flicker of a smile. Rises. A BODYGUARD \n",
      "opens double doors which give onto a LAVISH PARTY.\n",
      "\n",
      "SAITO\n",
      "\n",
      "Gentlemen. Enjoy your evening as I \n",
      "consider your proposal.\n",
      "\n",
      "They watch Saito leave. Arthur turns to Cobb, worried-\n",
      "\n",
      "He knows.\n",
      "\n",
      "ARTHUR\n",
      "\n",
      "Cobb motions silence. A TREMOR starts, they steady their \n",
      "glasses, Cobb glances at his watch- THE SECOND HAND IS \n",
      "FROZEN.\n",
      "\n",
      "ARTHUR\n",
      "What’s going on up there?\n",
      "\n",
      "And we-\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "FILTHY BATHROOM - DAY (FEELS LIKE DIFFERENT TIME)\n",
      "\n",
      "\n",
      "************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = query(vector)\n",
    "for doc in docs:\n",
    "    print(doc['score'], doc['id'])\n",
    "    print(doc['text'])\n",
    "    print('\\n\\n************************************************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
